---
title: "Aula 10 - Econometria de Séries Temporais"
author: "João Ricardo F. de Lima"
date: "`r format(Sys.time(), '%d de %B de %Y.')`"
output: 
    html_document:
        theme: flatly
        number_sections: yes
        highlight: textmate
#        includes: 
#          in_header: "header.html"
        toc: yes
        toc_float:
          collapsed: yes
          smooth_scroll: yes 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo       = TRUE,
  warning    = FALSE,
  message    = FALSE,
  fig.width  = 10, 
  fig.height = 7,
  fig.align  = "center",
  comment    = "#",
  size       = "normalsize"
  )

#Linhas precisam de ajuste semanal: 30, 104, 201, 204
```

<br>

# Análise de Séries Temporais Multivariadas

<br>

Na análise univariada de séries temporais o objetivo era, basicamente, entender a dependência dinâmica de uma série $X_{t}$, isto é, a dependência de $X_{t}$ com os seus valores passados $(X_{t-1}, X_{t-2},...)$.

Contudo, existem variáveis que são definidas dentro de um sistema e é um erro modelar estes processos de maneira puramente autorregressiva ou não controlando a dinâmica intertemporal: PIB, Consumo, Investimento, Gastos do Governo são definidos simultaneamente, por exemplo.  

Essas questões, bastante pertinentes no dia a dia, são tratadas dentro da **análise multivariada de séries temporais**.

São objetivos básicos da análise multivariada de séries temporais:

1) Estudar as relações dinâmicas entre séries diversas;
2) Melhorar as previsões sobre uma variável específica.

Seja $z_{t} = (z_{1t}, z_{2t}, ..., z_{kt})^{'}$ um vetor de dimensão $k$ que contém séries temporais observadas em um período de tempo comum. Por exemplo, $z_{1t}$ é o PIB trimestral brasileiro e $z_{2t}$ é a taxa de desemprego também trimestral. 

Estudando $z_{1t}$ e $z_{2t}$ conjuntamente, pode-se verificar a dependência contemporânea e passada que existe entre essas duas variáveis. Pode-se verificar o quanto um choque no PIB afeta a taxa de desemprego e quanto tempo isso tende a durar. Pode-se estar interessados na relação entre os desembolsos do BNDES e a taxa de investimento da economia brasileira. Será que aumentar os desembolsos ao banco eleva o investimento no país?

<br>

## Exemplo de séries que possuem correlação

<br>

``` {r econ10_1, warning=FALSE, message=FALSE }
library(vars)
library(aod)
library(urca)
library(stargazer)
library(forecast)
library(ggplot2)
#library(ggthemr)
library(gridExtra)
library(readxl)
library(scales)
#ggthemr('light')

# Os dados do BNDES estão em http://bit.ly/2pHg5wc. Depois de baixar e salvar na pasta correta, é importar os dados

setwd('/Users/jricardofl/Dropbox/tempecon/facape/econometria2')

data <- read_xls("bndes.xls", range = "AX5:AX264")
colnames(data) <- "desembolso"
data <- as.data.frame(data)

#Retira os valores faltantes
data <- na.omit(data)

#Retira os somatórios
data <- data[-c(13,13*2,13*3,13*4,13*5,13*6,13*7,13*8,13*9,13*10,13*11,
                13*12,13*13,13*14,13*15,13*16,13*17,13*18),]

data <- as.data.frame(data)

#Seta como série temporal
desembolso <- ts(data, start=c(2000,1), freq=12)

#Limita até o final de 2016
desembolso <- window(desembolso, end=c(2016,12))

anual <- desembolso
anual <- (anual+lag(anual,-1)+lag(anual,-2)+lag(anual,-3)+
              lag(anual,-4)+lag(anual,-5)+lag(anual,-6)+
              lag(anual,-7)+lag(anual,-8)+lag(anual,-9)+
              lag(anual,-10)+lag(anual,-11))
desembolso12 <- anual

# Dados do PIB e da taxa de investimento

data2 <- ts(read.csv2('data-1.csv', sep=';', dec=',')[,-1],
            start=c(1996,4), freq=4)

# Consolidando os dados
bndes <- ts(aggregate(desembolso12, nfrequency = 4, FUN=mean),
                start=c(2001,1), freq=4)

# Juntando as bases de dados
data <- ts.intersect(data2, bndes)
data <- cbind(data[,3]/data[,1]*100, data[,2])
colnames(data) <- c('BNDES', 'Investimento')

#Plot dos dois gráficos
g1 <- autoplot(data[,1])+
  geom_line(size=.8, colour='darkblue')+
  scale_x_discrete(limits=2001:2017)+
  labs(title='Desembolsos do BNDES')+
  xlab('')+ylab('% PIB')
g2 <- autoplot(data[,2])+
  geom_line(size=.8, colour='red')+
  scale_x_discrete(limits=2001:2017)+
  labs(title='Taxa de Investimento')+
  xlab('')+ylab('% PIB')
grid.arrange(g1, g2,
             top = "",
            layout_matrix = matrix(c(1,1,2,2), 
                                   ncol=2, byrow=TRUE))

# Correlação entre Desembolsos do BNDES vs. Taxa de Investimento
dates <- seq(as.Date('2001-01-01'), as.Date('2016-12-01'), by='3 month')
df <- data.frame(time=dates, bndes=data[,1], investimento=data[,2])
ggplot(df, aes(bndes, investimento))+
  geom_point(colour='black', size=5, shape=20)+
  geom_smooth(method = 'lm')+
  xlab('Desembolsos do BNDES')+
  ylab('Taxa de Investimento')+
  labs(title='Desembolsos do BNDES vs. Taxa de Investimento')

cor(data)
```

<br>

A correlação entre as variáveis é 0.87, bastante elevada. 

<br>

## Modelos Multivariados

<br>

Contudo, não é o bastante para se identificar a natureza da relação entre elas. Algumas questões devem ser levadas em consideração. Suponha que as series sejam estacionárias em nível. Pode-se, nesse caso, estimar um **Vetor Autoregressivo (VAR)** de primeira ordem, de modo que: 

<br>

$$
FBCF_{t} = \delta_{1} + \gamma_{11}FBCF_{t-1} + \gamma_{12}BNDES_{t-1} + \varepsilon_{1t}
$$

<br>

$$
BNDES_{t} = \delta_{2} + \gamma_{21}BNDES_{t-1} + \gamma_{22}FBCF_{t-1} + \varepsilon_{2t}
$$

<br>

### O Modelo VAR

<br>

O VAR(1) vai descrever a evolução dinâmica da interação entre a FBCF e os desembolsos do BNDES.

O modelo VAR foi desenvolvido por Christopher Sims em um artigo publicado em 1980 na qual se propunha tratar todas as variáveis do sistema simetricamente, sem fazer hipótese sobre a estrutura de correlação entre elas.

Uma vez estimado esse modelo, pode-se perguntar se existe causalidade nessa relação, isto é, se os desembolsos do BNDES de fato ajudam a prever a taxa de investimento, se o contrário ocorre ou se há uma simultaneidade. Nesse último caso, diz-se que existe uma causalidade bidirecional.

Para definir o modelo VAR pode-se apresentar uma especificação bivariada simples. A idéia é que não sabendo se há causalidade mútua, se parte de um modelo em que as inovações contemporâneas de um processo afetam o outro.

<br>

$$
y_{1,t}=\alpha_1-\delta_2y_{2,t}+\beta_1y_{1,t-1}+\beta_2y_{2,t-1}+\epsilon_{1,t}
$$

$$
y_{2,t}=\alpha_2-\delta_1y_{1,t}+\beta_2y_{2,t-1}+\beta_1y_{1,t-1}+\epsilon_{2,t}
$$
<br>

No sistema acima, os termos $y_{1,t}$ e $y_{2,t}$ representam a dinâmica contemporânea, relaxando a hipótese de restrição de *feedback*. 

O modelo acima está no denominado modelo estrutural, devido a presença do termo contemporâneo no lado direito de cada equação.

Para colocá-lo na forma reduzida, se escreve o modelo na forma matricial a partir do rearranjo;

<br>
$$
y_{1,t}+\delta_2y_{2,t}=\alpha_1+\beta_1y_{1,t-1}+\beta_2y_{2,t-1}+\epsilon_{1,t}
$$

<br>
$$
y_{2,t}+\delta_1y_{1,t}=\alpha_2+\beta_2y_{2,t-1}+\beta_1y_{1,t-1}+\epsilon_{2,t}
$$
<br>
a partir do qual se obtém:
<br>

$$
\left[\begin{array}{cc}
	1 & \delta_2\\
	\delta_1 & 1
	\end{array}\right] 	\left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_t = \left[\begin{array}{c}
	\alpha_1\\
	\alpha_2
	\end{array}\right]+ \left[\begin{array}{cc}
	\beta_1 & \beta_2 \\
	\beta_2 & \beta_1
	\end{array}\right] \left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_{t-1}+\left[\begin{array}{c}
	\epsilon_1 \\
	\epsilon_2
	\end{array}\right]_t
$$

<br>

que pode ser simplificado como

<br>

$$
	Ay_t=\alpha+B^*y_{t-1}+\epsilon_t
$$
<br>

se a equação acima for multiplicada pela inversa da Matriz A, ou seja,

<br>

$$
A^{-1}=\left[\begin{array}{cc}
	1 & \delta_2\\
	\delta_1 & 1
	\end{array}\right]^{-1}= 	\frac{1}{1-\delta_1\delta_2}\left[\begin{array}{cc}
	1 & -\delta_1\\
	-\delta_2 & 1
	\end{array}\right]
$$ 

<br>

De onde se obtém

<br>
$$
y_t=a+By_{t-1}+e_t,
$$

<br>

a chamada forma reduzida, em que $a=A^{-1}\alpha$, $B=A^{-1}B^*$ e $e_t=A^{-1}\epsilon_t$

No Modelo VAR todas as variáveis são consideradas endógenas e determinadas de forma dinâmica pelos valores defasados. 

Se tem uma equação para cada variável em função de seus valores defasados e dos valores defasados das outras variáveis. 

Um VAR tem duas dimensões: 
a) número de variáveis =k; 
b)número de defasagens =p.

O estimador de MQO pode ser aplicado a cada equação individualmente.

Um modelo VAR precisa ser estável. A estabilidade do VAR é definida pelas suas raízes características. Se o VAR não for estável, não tem sentido ser estimado.

A estabilidade de um VAR pode ser examinada calculando as raízes características de:

<br>

$$
(I+B+B^2+ \dots+B^k)y_t=\sum_{i=0}^{\infty}B^i\epsilon_{t-1}
$$
<br>

O polinômio característico é definido por 

$$
\Pi(z)=(I+B+B^2+ \dots+B^k)
$$

As raízes de $|\Pi(z)|=0$ informarão sobre o processo ser ou não ser estacionário.

A condição necessária e suficiente para a estabilidade do VAR é que todas as raízes características estejam fora do círculo unitário.

Estacionariedade e estabilidade são duas propriedades fortemente relacionadas. No caso de modelos VAR, tal relação se dá pelo fato de que modelos VAR estáveis são sempre estacionários.

A negativa dessa informação não é verdadeira. Contudo, processos instáveis não tem interesse econômico.

Considere o modelo abaixo:

<br>

$$
\left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_t = \left[\begin{array}{c}
	0.5\\
	1.0
	\end{array}\right]+ \left[\begin{array}{cc}
	0.7 & 0.4 \\
	0.2 & 0.3
	\end{array}\right] \left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_{t-1}+\left[\begin{array}{c}
	\epsilon_1 \\
	\epsilon_2
	\end{array}\right]_t
$$
<br>

Este processo está simulado na figura abaixo:

<br>

``` {r econ10_2, warning=FALSE, message=FALSE }
# pacotes necessários 
library(dse)

n <- 500
r <- 0.7
set.seed(1)
Z1 <- rnorm(n)
Z2 <- rnorm(n)

E1 <- Z1
E2 <- r*Z1 + sqrt(1-r^2)*Z2

A <- matrix(c(.7,.2,.4,.3),2,2)

y_1 = y_2 <- rep(0,n)
for(t in 2:n){
  y_1[t] <- A[1,1]*y_1[t-1] + A[1,2]*y_2[t-1] + E1[t]
  y_2[t] <- A[2,1]*y_1[t-1] + A[2,2]*y_2[t-1] + E2[t]
}

# Figura 8.1
plot(y_1, type = "l", lty = 1, ylim = c(-6,6), ann = FALSE)
lines(y_2,lty = 3, col = "red")
```

<br>

Estes processos apresentam dinâmica comum. É dito estável. 

Para obter um processo não estável basta que as raízes sejam unitárias:

<br>

$$
\left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_t =  \left[\begin{array}{cc}
	1 & 0 \\
	0 & 1
	\end{array}\right] \left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_{t-1}+\left[\begin{array}{c}
	\epsilon_1 \\
	\epsilon_2
	\end{array}\right]_t
$$

<br>

Este processo está simulado na figura abaixo:

<br>

``` {r econ10_3, warning=FALSE, message=FALSE }
# A outra  matriz "A" abaixo gera o processo do sistema (8.14).

A = matrix(c(1,0,0,1),2,2)

y_3 = y_4 <- rep(0,n)

for(t in 2:n){
   y_3[t] <- A[1,1]*y_3[t-1] + A[1,2]*y_4[t-1] + E1[t]
   y_4[t] <- A[2,1]*y_3[t-1] + A[2,2]*y_4[t-1] + E2[t]
}
 
# # Figura 8.2
plot(y_3, type = "l", lty = 1, ylim = c(-15,20), ann = FALSE)
 lines(y_4,lty = 3, col = "red")
```

<br>

Estes processos não apresentam dinâmica comum, tendem a se descolar. É dito instável.

<br>

### Determinação da ordem de defasagem

<br>

Uma vez de posse dos nossos dados, já devidamente tratados, um problema imediato é determinar a ordem $p$ de defasagem do nosso modelo. Isso é feito empiricamente pela análise de **critérios de informação**. Os mais conhecidos são os critérios de Akaike, Hannan-Quinn e Schwarz, sendo determinado como se segue:

$$
AIC(p) = log det (\Sigma_{u}(p)) + \frac{2}{T} p K^{2}
$$ 

$$
HQ(p) = log det (\Sigma_{u}(p)) + \frac{2log(log(T))}{T} p K^{2}
$$

$$
SC(p) = log det (\Sigma_{u}(p)) + \frac{log(T)}{T} p K^{2} 
$$
onde $\Sigma_{u}(p) = T^{-1}\sum_{t=1}^{T} \hat{u_{t}} {\hat{u}_{t}}'$.
No R esses critérios estão implementados na função `VARselect` do pacote `vars`.

<br>

A determinação do lag é dada por:
  
<br>

``` {r econ10_4, warning=FALSE, message=FALSE }
# Estruturação dados com como um objeto "ts" e ajuste em um modelo VAR.
data <- as.ts(cbind(y_1,y_2))

# Estimação da número de lags e do processo
VARselect(data, lag.max = 6, type = "none")
```

<br>
  
A primeira parte da saída indica o número ótimo de defasagens para cada critério, seguido pela tabela com o valor de cada um para cada defasagem.

A melhor defasagem é dada pelo menor valor do critério. Isto é tudo que se precisa para estimar um modelo VAR.

<br>
  
### Estimação do Modelo VAR(1)
  
<br>
  
O modelo VAR (1) estimado pelo método dos Mínimos Quadrados Ordinários é:
  
<br>
  
``` {r econ10_5, warning=FALSE, message=FALSE }
# Estruturação dados com como um objeto "ts" e ajuste em um modelo VAR.
(model1 <- VAR(data, p = 1, type = "none"))
```

<br>

Abaixo são apresentados os testes de autocorrelação, o de heterocedasticidade e os autovalores para verificar a estabilidade. 

<br>

``` {r econ10_6, warning=FALSE, message=FALSE }
# Diagnóstico 

serial.test(model1)
arch.test(model1)
vars::roots(model1)

# guardar autovalores do processo
autoval <- vars::roots(model1)

# Figura 
x <- seq(-1,1,length = 1000)
y1 <- sqrt(1-x^2)
y2 <- -sqrt(1-x^2)
plot(c(x,x),c(y1,y2),xlab='Parte Real',ylab='Parte Complexa',type='l',main='Circulo Unitario',ylim=c(-2,2),xlim=c(-2,2))
abline(h = 0)
abline(v = 0)
points(autoval, Im(autoval),pch=19)
legend(-2.0,-1.5,legend="Autovalores",pch=19)
```

<br>

### Função Impulso Resposta

<br>

Como visto, a modelagem VAR procura identificar a relação dinâmica existente em um conjunto previamente definido de variáveis.

Dentro desse tipo de abordagem, pode ser interessante para o pesquisador verificar o impacto de um **choque** ou **impulso** em uma variável sobre as outras.

Esse tipo de exercício é conhecido na literatura como **análise de impulso-resposta**. A ideia é verificar a resposta esperada na variável $y_{i,t+s}$ da mudança em uma unidade na variável $y_{j,t}$.

Em outras palavras, dá-se um choque em $t$ na variável $y_{j}$ e observa-se o efeito desse choque sobre a variável $y_{i}$ ao longo de $t+s$. Esses efeitos, ademais, podem ser acumulados.

<br>

Considere as equações já vistas anteriormente

<br>

$$
y_{1,t}=\alpha_1-\delta_2y_{2,t}+\beta_1y_{1,t-1}+\beta_2y_{2,t-1}+\epsilon_{1,t}
$$

<br>

$$
y_{2,t}=\alpha_2-\delta_1y_{1,t}+\beta_2y_{2,t-1}+\beta_1y_{1,t-1}+\epsilon_{2,t}
$$

<br>

Se forem reescritas na forma matriz como um processo de médias móveis, tem-se

<br>

$$
\left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_t =  \left[\begin{array}{c}
	\bar{y}_1  \\
	\bar{y}_2 
	\end{array}\right] \sum_{i=0}^{\infty}B^i +\left[\begin{array}{c}
	\epsilon_1 \\
	\epsilon_2
	\end{array}\right]_{t-1}
$$
Como o termo de erro é dado por

$$
\left[\begin{array}{c}
	e_1 \\
	e_2
	\end{array}\right]_{t-1}= 	\frac{1}{1-\delta_1\delta_2}\left[\begin{array}{cc}
	1 & -\delta_1\\
	-\delta_2 & 1
	\end{array}\right]\left[\begin{array}{c}
	\epsilon_1 \\
	\epsilon_2
	\end{array}\right]_{t-1}
$$

<br>

Se tem 


<br>

$$
\left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_t =  \left[\begin{array}{c}
	\bar{y}_1  \\
	\bar{y}_2 
	\end{array}\right]+ \frac{1}{1-\delta_1\delta_2}\sum_{i=0}^{\infty}B^i \left[\begin{array}{cc}
	1 & -\delta_1\\
	-\delta_2 & 1
	\end{array}\right]\left[\begin{array}{c}
	\epsilon_1 \\
	\epsilon_2
	\end{array}\right]_{t-1}
$$
<br>

Que pode ser rearranjado para 

$$
	\left[\begin{array}{c}
	y_1 \\
	y_2
	\end{array}\right]_t =  \left[\begin{array}{c}
	\bar{y}_1  \\
	\bar{y}_2 
	\end{array}\right]+ \sum_{i=0}^{\infty} \left[\begin{array}{cc}
	\phi_{1,1}(i) & \phi_{1,2}(i)\\
	\phi_{2,1}(i) & \phi_{2,2}(i)
	\end{array}\right]\left[\begin{array}{c}
	\epsilon_1 \\
	\epsilon_2
	\end{array}\right]_{t-1}
$$

Onde cada $\phi_{i,j}$ é uma função de impulso-resposta e seu gráfico é uma maneira prática de visualizar o comportamento de choques entre as variáveis do modelo. 

Em modelos estáveis, espera-se que as respostas a esses choques, que chamam impulsos, convirjam para zero em tempo finito, preferencialmente em poucos lags.

Vale observar que $\phi_{i,j}(0)$, a resposta instantânea, é chamado de multiplicar de choque.

O gráfico de $\phi_{i,j}(t)$ é formado por uma sequência de valores de tempo (i.e, t=0,1,2,...,n) assumindo na ultima equação do slide anterior que $e_t=1$.

Dessa maneira, a interpretação se inicia assumindo um choque de uma unidade na variável j, com a respectiva resposta na variável "i" dada pelo comportamento gráfico.

<br>

``` {r econ10_7, warning=FALSE, message=FALSE }
# Função impulso-resposta 
# FIR, PREVISAO E DECOMPOSICAO

# Elaboração da Figura 

# resposta do choque em y1
model1.irf <- irf(model1, impulse = "y_1", n.ahead = 40, boot = TRUE)
# resposta do choque em y2
model2.irf <- irf(model1, impulse = "y_2", n.ahead = 40, boot = TRUE)

par(mfcol=c(2,2), mar=c(0,4,0,0), oma=c(5,3,5,3))

# Figura (a)
plot.ts(model1.irf$irf$y_1[,1], axes=F, oma.multi = c(0,0,5,0),
        ylab='y_1', ylim=c(-0,1))
lines(model1.irf$Lower$y_1[,1], lty=2, col='red')
lines(model1.irf$Upper$y_1[,1], lty=2, col='red')
axis(side=2, las=2, ylab='')
abline(h=0, col='red')
box()
mtext("Resposta do Choque em y_1", line = 2)

plot.ts(model1.irf$irf$y_1[,2], axes=F, oma.multi = c(0,0,5,0),
        ylab='y_2', ylim=c(-0,1))
lines(model1.irf$Lower$y_1[,2], lty=2, col='red')
lines(model1.irf$Upper$y_1[,2], lty=2, col='red')
axis(side=1, las=1)
axis(side=2, las=2)
abline(h=0, col='red')
box()
mtext("95% Bootstrap CI, 100 runs", side=1, line = 3)

# Figura (b)
plot.ts(model2.irf$irf$y_2[,1], axes=F, oma.multi = c(0,0,5,0),
        ylab='', ylim=c(-0,1))
lines(model2.irf$Lower$y_2[,1], lty=2, col='red')
lines(model2.irf$Upper$y_2[,1], lty=2, col='red')
axis(side=2, las=2, ylab='')
abline(h=0, col='red')
box()
mtext("Resposta do Choque em y_2", line = 2)

plot.ts(model2.irf$irf$y_2[,2], axes=F, oma.multi = c(0,0,5,0),
        ylab='', ylim=c(-0,1))
lines(model2.irf$Lower$y_2[,2], lty=2, col='red')
lines(model2.irf$Upper$y_2[,2], lty=2, col='red')
axis(side=1, las=1)
axis(side=2, las=2)
abline(h=0, col='red')
box()
mtext("95% Bootstrap CI, 100 runs", side=1, line = 3)


# Elaboração da Figura

# resposta do choque em y1
model1.irf <- irf(model1, impulse = "y_1", n.ahead = 40, boot = TRUE, cumulative = T)
# resposta do choque em y2
model2.irf <- irf(model1, impulse = "y_2", n.ahead = 40, boot = TRUE, cumulative = T)

par(mfcol=c(2,2), mar=c(0,4,0,0), oma=c(5,3,5,3))

# Figura (a)
plot.ts(model1.irf$irf$y_1[,1], axes=F, oma.multi = c(0,0,5,0),
        ylab='y_1', ylim=c(-0,8))
lines(model1.irf$Lower$y_1[,1], lty=2, col='red')
lines(model1.irf$Upper$y_1[,1], lty=2, col='red')
axis(side=2, las=2, ylab='')
abline(h=0, col='red')
box()
mtext("Cumulative Response from y_1", line = 2)

plot.ts(model1.irf$irf$y_1[,2], axes=F, oma.multi = c(0,0,5,0),
        ylab='y_2', ylim=c(-0,8))
lines(model1.irf$Lower$y_1[,2], lty=2, col='red')
lines(model1.irf$Upper$y_1[,2], lty=2, col='red')
axis(side=1, las=1)
axis(side=2, las=2)
abline(h=0, col='red')
box()
mtext("95% Bootstrap CI, 100 runs", side=1, line = 3)

# Figura (b)
plot.ts(model2.irf$irf$y_2[,1], axes=F, oma.multi = c(0,0,5,0),
        ylab='', ylim=c(-0,8))
lines(model2.irf$Lower$y_2[,1], lty=2, col='red')
lines(model2.irf$Upper$y_2[,1], lty=2, col='red')
axis(side=2, las=2, ylab='')
abline(h=0, col='red')
box()
mtext("Cumulative Response from y_2", line = 2)

plot.ts(model2.irf$irf$y_2[,2], axes=F, oma.multi = c(0,0,5,0),
        ylab='', ylim=c(-0,8))
lines(model2.irf$Lower$y_2[,2], lty=2, col='red')
lines(model2.irf$Upper$y_2[,2], lty=2, col='red')
axis(side=1, las=1)
axis(side=2, las=2)
abline(h=0, col='red')
box()
mtext("95% Bootstrap CI, 100 runs", side=1, line = 3)
```

<br>

### Decomposição da variância

<br>

Um último tópico importante é a decomposição de variância, isto é, o quanto da variância de uma variável do nosso conjunto é explicado pelas demais variáveis. No R, ela é implementada com a função ``fevd``.

Em linhas gerais, a função retorna o quanto a variação (percentual) do erro de previsão é atribuída a cada variável para uma sequencia de valores no tempo.

A variância total dos erros de previsão é decomposta em duas componentes, neste caso em análise, uma relacionada com $y_1$ e a outra com $y_2$.

Na prática, esta análise nos ajuda a verificar quais variáveis são realmente importantes quando o objetivo é realizar previsões.

Quanto maior for a contribuição percentual de uma variável para a variação total da outra, mais importante ela é para se realizar boas previsões da variável da qual realiza-se a decomposição. 

<br>

``` {r econ10_8, warning=FALSE, message=FALSE }
# Decomposição da variância 

fevd.model1 <- fevd(model1, n.ahead = 7)
plot(fevd.model1, main="")
```

<br>

Os choques em $y_1$ afetam mais $y_1$ do que $y_2$. Já no caso de choque em $y_2$, tem bastante efeito em $y_1$.

<br>

## Previsão no Modelo VAR

<br>

No R, duas maneiras para gerar previsões estão implantadas em predict() e fanchart(), a primeira retorna os pontos médios dos intervalos de confiança para cada previsão enquanto a segunda produz os intervalos como áreas sombreadas.

``` {r econ10_9, warning=FALSE, message=FALSE }
# Previsões

#  previsão a partir de 'fanchart'
model1.y_1 <- predict(model1, n.ahead = 10, ci = 0.95)
fanchart(model1.y_1, xlim = c(450,505), main = c("Fanchart de y_1", "Fanchart de y_2"))
plot(model1.y_1)
```

<br>

## Teste de Causalidade de Granger

O termo "causalidade de Granger" significa que há uma relação de antecedência-defasagem entre as variáveis de séries de tempo multivariadas. Em outras palavras, uma variável x vai ser dita que causa Granger em uma variável y, se os valores passados de x e valores passados de y forem úteis para prever y.

Testa se uma variável endógena pode ser tratada como exógena. Para cada equação do VAR, é calculado uma estatística de $\chi^2$ para a significância conjunta de cada uma das variáveis endógenas defasadas na equação.

A estimação do VAR deve ser feita antes do teste de causalidade de Granger, uma vez que a análise está verificando a causalidade entre várias variáveis.

Testa-se a hipótese nula de que os coeficientes estimados da variável exogena defasada são conjuntamente iguais à zero. Não rejeitar essa possibilidade é equivalente a não rejeitar a hipótese de que a variável Y não causa a Granger a variável X.

São estimadas regressões bivariadas na forma:

$$
y_t=\alpha_{0}+\alpha_{1}y_{t-1}+\dots+\beta_1x_{t-1}+\dots+\varepsilon_t
$$

$$
x_t=\alpha_{0}+\alpha_{1}x_{t-1}+\dots+\beta_1y_{t-1}+\dots+\mu_t
$$
para todos os possíveis pares de variáveis endógenas. O teste realizado conjuntamente, para cada equação, é:

$$
\beta_1=\beta_2=\dots=0
$$

As hipóteses nulas são que x não causa a Granger y na primeira equação e que y não causa a Granger x na segunda regressão.

``` {r econ10_10, warning=FALSE, message=FALSE }
# Causalidade de Granger
causality(model1)$Granger
```
<br>

## Exemplo Análise Macro I

``` {r econ10_11, warning=FALSE, message=FALSE }
# https://analisemacro.com.br/data-science/o-ovo-ou-a-galinha-teste-de-causalidade-de-granger-na-granja
# Causalidade de Granger

# Pacotes ---------

# Carregar pacotes
library(lmtest)
library(magrittr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(ggtext)
library(purrr)
library(forecast)
library(tsibble)
library(downloader)


# Dados ---------

# Dataset de ovos/galinhas (veja documentação ?lmtest::ChickEgg)
dados <- lmtest::ChickEgg
dados_tbl <- dados %>%
  dplyr::as_tibble() %>%
  dplyr::mutate(
    date = seq(from = tsp(dados)[1], to = tsp(dados)[2], by = tsp(dados)[3])
    )

# Visualização dos dados
dados_tbl %>%
  tidyr::pivot_longer(cols = -"date") %>%
  dplyr::mutate(
    name = dplyr::recode(name, "chicken" = "Galinhas", "egg" = "Ovos")
    ) %>%
  ggplot2::ggplot() +
  ggplot2::aes(x = date, y = value, color = name) +
  ggplot2::geom_line(size = 1, show.legend = FALSE) +
  ggplot2::facet_wrap(facets = ~name, scales = "free") +
  ggplot2::scale_y_continuous(
    labels = scales::label_number(big.mark = ".", decimal.mark = ",")
    ) +
  ggplot2::scale_color_manual(values = c("#282f6b", "#b22200")) +
  ggplot2::labs(
    title    = "O que veio primeiro, o ovo ou a galinha?",
    subtitle = "Séries anuais de população de galinhas em 1º de dezembro e produção de milhões de dúzias de ovos nos EUA.",
    y        = NULL,
    x        = NULL,
    caption  = "**Dados**: Zeileis e Hothorn (2002) | **Elaboração**: analisemacro.com.br"
    ) +
  ggplot2::theme_light() +
  ggplot2::theme(
    plot.title       = ggplot2::element_text(size = 20, face = "bold", color = "#282f6b"),
    plot.subtitle    = ggplot2::element_text(size = 14),
    plot.caption     = ggtext::element_textbox_simple(size = 10, margin = ggplot2::margin(10)),
    axis.text        = ggplot2::element_text(size = 12, face = "bold"),
    strip.background = ggplot2::element_blank(),
    strip.text       = ggplot2::element_text(size = 12, face = "bold", color = "black")
    )

# Número de diferenças para tornar a série estacionária----------------------------
dados_tbl <- tsibble::as_tsibble(dados_tbl, index = date)

feasts::unitroot_ndiffs(dados_tbl$chicken)
feasts::unitroot_ndiffs(dados_tbl$egg)

# 3) Diferencia as séries
dados_chk_diff <- diff(dados_tbl$chicken)
dados_egg_diff <- diff(dados_tbl$egg)

dados_diff <- cbind(dados_chk_diff, dados_egg_diff)

dados_diff <- ts(
  data      = dados_diff,
  start     = 1931,
  frequency = 1
  )


# Teste de causalidade de Granger -----------------------------------------

# Aplicar o teste de Causalidade de Granger
# H0: série X não Granger-causa série Y
# H1: série X Granger-causa série Y
lmtest::grangertest(
  y     = dados_diff[, "dados_chk_diff"],
  x     = dados_diff[, "dados_egg_diff"],
  order = 4 # lags/defasagens, de 1:5 resultados são similares
  )
# p-valor deu 0.006414 -> hipótese nula rejeitada a 1% (há precedência temporal,
# série X causa no sentido de Granger série Y ou "ovos precedem galinhas")
```

``` {r econ10_12, warning=FALSE, message=FALSE }

# Teste em reverso
lmtest::grangertest(
  y     = dados_diff[, "dados_egg_diff"],
  x     = dados_diff[, "dados_chk_diff"],
  order = 4
  )
# p-valor deu 0.8881 -> falha-se em rejeitar a hipótese nula (não há precedência temporal,
# série X não causa no sentido de Granger a série Y ou "galinhas não precedem ovos")

```

<br>

## Exemplo Análise Macro II

```{r econ10_13, warning=FALSE, message=FALSE }
# https://analisemacro.com.br/data-science/dicas-de-rstats/analise-de-impulso-resposta-em-series-financeiras/

# Pacotes -----------------------------------------------------------------

# Carregar pacotes/dependências
library(magrittr)   # CRAN v2.0.2
library(GetBCBData) # CRAN v0.6
library(ipeadatar)  # CRAN v0.1.6
library(lubridate)  # CRAN v1.8.0
library(tidyr)      # CRAN v1.2.0
library(dplyr)      # CRAN v1.0.8
library(tsibble)    # CRAN v1.1.1
library(purrr)      # CRAN v0.3.4
library(forecast)   # CRAN v8.16
library(ggplot2)    # CRAN v3.3.5
library(vars)       # CRAN v1.5-6

# Dados -------------------------------------------------------------------

# |-- Coleta e pré tratamento --|

# PIB mensal - Valores correntes - R$ milhões (BCB)
# Taxa de juros - Selic acumulada no mês anualizada base 252 - % a.a.
# Índice Nacional de Preços ao Consumidor Amplo (IPCA) - 	% a.m.
df_bcb <- GetBCBData::gbcbd_get_series(
  id = c(
    "pib_mensal" = 4380,
    "selic"      = 4189,
    "ipca"       = 433
  ),
  first.date = lubridate::ymd("2003-12-01"),
  use.memoise = FALSE
) %>%
  tidyr::pivot_wider(
    id_cols     = "ref.date",
    names_from  = "series.name",
    values_from = "value"
  ) %>%
  dplyr::rename("date" = "ref.date") %>%
  dplyr::mutate(date = tsibble::yearmonth(.data$date))

# Taxa de câmbio real bilateral - IPA-DI - BR/US: índice (média 2010 = 100)
# Ibovespa - Índice de ações - Fechamento - Anbima - % a.m.
# EMBI+ Risco-Brasil - ponto-base
# Índice Nacional de Preços ao Consumidor Amplo (IPCA) - Índice (dez. 1993 = 100)
codes_ipea <- c(
  "ibovespa"    = "ANBIMA12_IBVSP12",
  "cambio_real" = "GAC12_TCEREUA12",
  "embi_br"     = "JPM366_EMBI366",
  "ipca_indice" = "PRECOS12_IPCA12"
)
df_ipea <- ipeadatar::ipeadata(codes_ipea) %>%
  tidyr::pivot_wider(
    id_cols     = "date",
    names_from  = "code",
    values_from = "value"
  ) %>%
  dplyr::select("date", dplyr::all_of(codes_ipea)) %>%
  dplyr::group_by(date = tsibble::yearmonth(.data$date)) %>%
  dplyr::summarise(
    dplyr::across(
      .cols = !dplyr::any_of("date"),
      .fns = ~mean(.x, na.rm = TRUE)
    ),
    .groups = "drop"
  )


# |-- Cruzar tabelas --|
df_fin_macro <- dplyr::left_join(
  x = df_ipea,
  y = df_bcb,
  by = "date"
) %>%
  dplyr::filter(lubridate::as_date(date) >= lubridate::ymd("2003-12-01")) %>%
  tidyr::drop_na()



# Deflacionamento ---------------------------------------------------------

# Deflacionar séries nominais (note que para a SELIC é mais apropriado a
# equação de Fisher, mas optamos por simplificar)
df_fin_macro %<>%
  dplyr::mutate(
    dplyr::across(
      .cols = c("pib_mensal", "ibovespa", "selic"),
      .fns = ~ipca_indice[date == dplyr::last(date)] / ipca_indice * .x
    )
  ) %>%
  dplyr::select(-"ipca_indice")

# Número de diferenças para tornar a série estacionária----------------------------
vars_ndiffs <- tsibble::as_tsibble(df_fin_macro, index = date)

feasts::unitroot_ndiffs(vars_ndiffs$ibovespa)
feasts::unitroot_ndiffs(vars_ndiffs$cambio_real)
feasts::unitroot_ndiffs(vars_ndiffs$embi_br)
feasts::unitroot_ndiffs(vars_ndiffs$pib_mensal)
feasts::unitroot_ndiffs(vars_ndiffs$selic)
feasts::unitroot_ndiffs(vars_ndiffs$ipca)
```

<br>

Importante observar que existem séries que são I(0) e séries que são I(1), ou seja, não são integradas de mesma ordem, não sendo possível estimar um modelo VAR.

<br>

```{r econ10_14, warning=FALSE, message=FALSE }
#Diferenciar as séries
df_fin_macro_d <- data.frame(vars_ndiffs$date[-1])
df_fin_macro_d$cambio_real <- diff(vars_ndiffs$cambio_real)
df_fin_macro_d$embi_br <- diff(vars_ndiffs$embi_br)
df_fin_macro_d$pib_mensal <- diff(vars_ndiffs$pib_mensal)
df_fin_macro_d$selic <- diff(vars_ndiffs$selic)
df_fin_macro_d$ibovespa <- vars_ndiffs$ibovespa[-1]
df_fin_macro_d$ipca <- vars_ndiffs$ipca[-1]

colnames(df_fin_macro_d)[1] <- "date"

# Visualização de dados ---------------------------------------------------

# Gráfico de linhas da séries
df_fin_macro_d %>%
  tidyr::pivot_longer(-"date") %>%
  ggplot2::ggplot() +
  ggplot2::aes(x = lubridate::as_date(date), y = value) +
  ggplot2::geom_line() +
  ggplot2::facet_wrap(~name, scales = "free")
```

<br>

```{r econ10_15, warning=FALSE, message=FALSE }
# Modelo VAR --------------------------------------------------------------

df_fin_macro <- df_fin_macro_d

# Seleção de defasagens VAR por critérios de informação
lags_var <- vars::VARselect(
  y       = df_fin_macro[-1],
  lag.max = 12,
  type    = "const"
)

lags_var

# Estimar modelo VAR
fit_var <- vars::VAR(
  y       = df_fin_macro[-1],
  p       = lags_var$selection["AIC(n)"],
  type    = "const",
  lag.max = 12,
  ic      = "AIC"
)


# Resultados do VAR
summary(fit_var)

# Impulso Resposta --------------------------------------------------------

# Obter os coeficientes de impulso resposta do VAR
# Exemplo 1: choque na SELIC e resposta no IBOVESPA
irf_var <- vars::irf(
  x        = fit_var,
  impulse  = "selic",
  response = "ibovespa",
  n.ahead  = 12
)

# Plotar gráfico de impulso resposta
lags = 1:13

df_irf <- data.frame(irf = irf_var$irf, lower = irf_var$Lower, upper = irf_var$Upper,
                     lags = lags)

colnames(df_irf) <- c('irf', 'lower', 'upper', 'lags')

df_irf 

```

<br>

```{r econ10_16, warning=FALSE, message=FALSE }

number_ticks <- function(n) {function(limits) pretty(limits, n)}

ggplot(data = df_irf,aes(x=lags,y=irf)) +
  geom_line(aes(y = upper), colour = 'lightblue2') +
  geom_line(aes(y = lower), colour = 'lightblue')+
  geom_line(aes(y = irf), size=.8)+
  geom_ribbon(aes(x=lags, ymax=upper, 
                  ymin=lower), 
              fill="blue", alpha=.1) +
  xlab("") + ylab("IBOVESPA") + 
  ggtitle("Resposta ao Impulso na SELIC") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),                    
        axis.ticks.x=element_blank(),
        plot.margin = unit(c(2,10,2,10), "mm"))+
  geom_line(colour = 'black')+
  scale_x_continuous(breaks=number_ticks(13))+
  theme_bw()

# interpretação: dado um choque de um desvio padrão na variável SELIC do modelo
# a variável IBOVESPA do modelo (retornos) diminuirá em cerca de 1,71 no primeiro
# período, dado que o coeficiente é significativo (intervalos de confiança fora
# do zero)
# ou seja, a interpretação é na mesma unidade da variável, como especificada no
# modelo... se o modelo estivesse especificado em log, a interpretação seria %
```

<br>

